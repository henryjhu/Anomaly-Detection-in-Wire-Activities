{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSC-680_Python.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP3A0TsYRYKl0wDYFrONczP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henryjhu/Anomaly-Detection-in-Wire-Activities/blob/main/DSC_680_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb3PbbWC0L51"
      },
      "source": [
        "# **DSC-680-Z1 Research Practicum** <BR> Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBzyuneg0nNU"
      },
      "source": [
        "## **Project Description**\n",
        "The research practicum involves on-site experiential learning in a research setting. This setting may be in the private or public sector, it may include such locations as education, governmental, non-governmental, or general\n",
        "research organization. The experience must provide students the opportunity to collect and analyze data, consider ethical implications of research, and draw empirically grounded conclusions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUE-xhQ40sNr"
      },
      "source": [
        "<b>Purpose:</b><br>\n",
        "Carry out both unsupervised and supervised machine learnings with the sample data.<br>\n",
        "<b>Universtiy Name:</b> Utica College <br>\n",
        "<b>Course Name:</b> DSC-680-Z1 Research Practicum <br>\n",
        "<b>Student Name:</b> Henry J. Hu <br>\n",
        "<b>Program Director Name:</b> Dr. McCarthy, Michael <br>\n",
        "<b>Runtime Environment:</b> Google Colab<br>\n",
        "<b>Programming Language:</b> Python <br>\n",
        "<b>Sample Data Frame:</b>\n",
        "A random sample of international wires belonging to 139 customers from 3 continents for the entire year of 2020.<br>\n",
        "<b> Last Update:</b> July 21st, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMMMqxrAEMnC"
      },
      "source": [
        "## **Mounting Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovr70FQWyvvY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGsaUOOmEZXJ"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEqZ5d75z_rg"
      },
      "source": [
        "# Importing libraries\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import quantile, where, random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import model_selection, preprocessing\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import IsolationForest, VotingClassifier, StackingClassifier\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import traceback\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pytz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUn_dKOdEYDh"
      },
      "source": [
        "## **Importing Data Into Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVumC16bF1U-"
      },
      "source": [
        "# Importing data and looking at head\n",
        "input_data = pd.read_csv(\"gdrive/MyDrive/sample_df_4M.txt\")\n",
        "input_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCKWyCr5Ep5x"
      },
      "source": [
        "## **Data Segregation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-zcgIh5GUS7"
      },
      "source": [
        "NN_103_df = input_data[(input_data['CONTINENT_CODE']=='NN') & (input_data['SWIFT_MSG_TYPE']==103)]\n",
        "NN_103_df.head()\n",
        "NN_103_df.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yh25P7wXWy1"
      },
      "source": [
        "NN_202_df = input_data[(input_data['CONTINENT_CODE']=='NN') & (input_data['SWIFT_MSG_TYPE']==202)]\n",
        "NN_202_df.head()\n",
        "NN_202_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JrlLjz3L7OU"
      },
      "source": [
        "EU_103_df = input_data[(input_data['CONTINENT_CODE']=='EU') & (input_data['SWIFT_MSG_TYPE']==103)]\n",
        "EU_103_df.head()\n",
        "EU_103_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BktPI-sqX9Ez"
      },
      "source": [
        "EU_202_df = input_data[(input_data['CONTINENT_CODE']=='EU') & (input_data['SWIFT_MSG_TYPE']==202)]\n",
        "EU_202_df.head()\n",
        "EU_202_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taSgSgYrXipu"
      },
      "source": [
        "AS_103_df = input_data[(input_data['CONTINENT_CODE']=='EU') & (input_data['SWIFT_MSG_TYPE']==103)]\n",
        "AS_103_df.head()\n",
        "AS_103_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tga3zfc5YJr7"
      },
      "source": [
        "AS_202_df = input_data[(input_data['CONTINENT_CODE']=='EU') & (input_data['SWIFT_MSG_TYPE']==202)]\n",
        "AS_202_df.head()\n",
        "AS_202_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PSlpuPRFJ0Q"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_XuatApFJ1_"
      },
      "source": [
        "## **Unsupervised Ensemble Learner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRST4IxARkIx"
      },
      "source": [
        "##################################################################################################################\n",
        "#\n",
        "# Purpose: Function to calculate outlier scores for a given input data set.\n",
        "# Machine learning method: Ensemble learner of Local Outlier Factor and Isolaion Forest.\n",
        "# Score to fraud label rule: A score smaller than -1 is fraud and greater than or equal to -1 is not fraud.\n",
        "#\n",
        "##################################################################################################################\n",
        "\n",
        "def ensemble_fun (df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.05):\n",
        "\n",
        "  # Include only the relavent independent varialbes\n",
        "  X=df[['TRXN_MONTH','TRANSACTION_AMOUNT']]\n",
        "  \n",
        "  # Center the data around the mean of 0\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaling=StandardScaler()\n",
        "  scaling.fit_transform(X)\n",
        "\n",
        "  # Initialize the log variable\n",
        "  class log:\n",
        "    def_tz = pytz.timezone('America/New_York')\n",
        "    def info(text):        \n",
        "        print(f'{datetime.now(log.def_tz).replace(microsecond=0)} : {text}');\n",
        "\n",
        "  # Initialize an enumerate list of estimators\n",
        "  estimator_list = {\n",
        "    # novelty=False because this is outlier detection.\n",
        "    # pairwise_n = 2 for Euclidian distance and 1 for Manhattan distance.\n",
        "    'LOF':LocalOutlierFactor(novelty=False, n_neighbors=n_neighbors_n, algorithm='auto', leaf_size=30, \n",
        "                             metric='minkowski', p=pairwise_n, metric_params=None, contamination=contamination_n),\n",
        "    'iForest':IsolationForest(n_estimators=n_estimators_n, random_state=random_state_n, max_samples=len(X), contamination=contamination_n)\n",
        "  }\n",
        "\n",
        "  # Input data frame size\n",
        "  n_rows_in = X.shape[0]\n",
        "  n_features_in = X.shape[1]\n",
        "\n",
        "  # Initializing score array\n",
        "  ensemble_scores = np.zeros([n_rows_in, len(estimator_list)])\n",
        "\n",
        "  # Ensemble via score averaging\n",
        "  log.info (f'Input data frame size: Rows = {n_rows_in}, Columns = {n_features_in}')\n",
        "\n",
        "  for i, (clf_name, clf) in enumerate(estimator_list.items()):\n",
        "    try:\n",
        "        clf.fit(X)\n",
        "        if clf_name == \"LOF\":\n",
        "            log.info(f'Fitting {clf_name}')\n",
        "            ensemble_scores[:, i] = clf.negative_outlier_factor_\n",
        "        else:\n",
        "            log.info(f'Fitting {clf_name}')\n",
        "            ensemble_scores[:, i] = clf.decision_function(X)\n",
        "    except:\n",
        "            log.info(traceback.print_exc())\n",
        "    else:    \n",
        "            log.info(f'{clf_name} is fitted successfully with {len(ensemble_scores)} scores')  \n",
        "\n",
        "  # Repalce NaN with 0's\n",
        "  ensemble_scores=np.nan_to_num(ensemble_scores) \n",
        "\n",
        "  # Removing rows where scores from either algorithm is 0\n",
        "  ensemble_scores = ensemble_scores[:,~np.all(ensemble_scores == 0.0, axis=0)] \n",
        "\n",
        "  # Averaging scores from both algorithms\n",
        "  score_by_avg = np.mean(ensemble_scores, axis = 1) \n",
        "\n",
        "  # Make a copy of final score array\n",
        "  pred_y = np.copy(score_by_avg) \n",
        "\n",
        "  score_min = min(pred_y)\n",
        "  score_max = max(pred_y)\n",
        "\n",
        "  log.info (f'Minimum Score = {score_min}, Maximum Score = {score_max}')\n",
        "\n",
        "  # Labeling all scores <-0.5 as fraud and >=-0.5 as non-fraud\n",
        "  pred_y[pred_y < -50] = -99\n",
        "  pred_y[pred_y >= -50] = 0.0\n",
        "  pred_y[pred_y == -99] = 1.0\n",
        "\n",
        "  fraud_ct = np.count_nonzero(pred_y == 1.0)\n",
        "  fraud_pct = fraud_ct/n_rows_in\n",
        "\n",
        "  log.info (f'Percentage of suspicious transactions: {fraud_pct}')\n",
        "\n",
        "  df_arr=df.to_numpy() # Converting the input data frame to array\n",
        "  df_arr_f=np.column_stack( (df_arr, pred_y)) # Add the scores to the input data frame\n",
        "\n",
        "  # Converting the combinded array back to a data frame\n",
        "  df_f = pd.DataFrame(df_arr_f, columns = ['TRANSACTION_ID','TRANSACTION_TIME','TRXN_MONTH','CLIENT_ID','COUNTRY_NAME','COUNTRY_CODE','CONTINENT_NAME',\t'CONTINENT_CODE','SWIFT_MSG_TYPE','AVG_TRXN_AMT','TRANSACTION_AMOUNT','FRAUD_LABEL']) \n",
        "\n",
        "  # Output data frame size\n",
        "  n_rows_o = df_f.shape[0]\n",
        "  n_features_o = df_f.shape[1]\n",
        "  log.info (f'Output data frame size: Rows = {n_rows_o}, Columns = {n_features_o}')\n",
        "\n",
        "  return df_f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxQ88y_MCLU1"
      },
      "source": [
        "NN_103_score_df = ensemble_fun (NN_103_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "NN_103_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWxsTUDyRdZo"
      },
      "source": [
        "NN_202_score_df = ensemble_fun (NN_202_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "NN_202_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3b-pASFGEPf"
      },
      "source": [
        "EU_103_score_df = ensemble_fun (EU_103_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "EU_103_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vtXdmFSRG-"
      },
      "source": [
        "EU_202_score_df = ensemble_fun (EU_202_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "EU_202_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHsYUK2S_Ba"
      },
      "source": [
        "AS_103_score_df = ensemble_fun (AS_103_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "AS_103_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfA1GNsOTL3i"
      },
      "source": [
        "AS_202_score_df = ensemble_fun (AS_202_df, n_neighbors_n=20, leaf_size=30, pairwise_n=2, n_estimators_n=100, random_state_n=42, contamination_n=0.01)\n",
        "AS_202_score_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp2e2KdtYtAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}