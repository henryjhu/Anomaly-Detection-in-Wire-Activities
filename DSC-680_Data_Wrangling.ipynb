{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DSC-680 Data Science Research Practicum** <br> Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Description**\n",
    "The research practicum involves on-site experiential learning in a research setting. This setting may be in the private or public sector, it may include such locations as education, governmental, non-governmental, or general\n",
    "research organization. The experience must provide students the opportunity to collect and analyze data, consider ethical implications of research, and draw empirically grounded conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Purpose:</b><br>\n",
    "Manipulate 139 data files and concatenate them into one single text file.<br>\n",
    "<b>Universtiy Name:</b> Utica College <br>\n",
    "<b>Course Name:</b> DSC-680-Z1 Research Practicum <br>\n",
    "<b>Student Name:</b> Henry J. Hu <br>\n",
    "<b>Program Director Name:</b> Dr. McCarthy, Michael <br>\n",
    "<b>Runtime Environment:</b> Google Colab<br>\n",
    "<b>Programming Language:</b> Python <br>\n",
    "<b>Data:</b>\n",
    "A real financial data set of over 12 million international wire transfers belonging to 139 customers transacted between the years 2019 and 2021 was provided for this research project<br>\n",
    "<b> Last Update:</b> July 21st, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><b>Import Libraries</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><b>Process and Merge Text Files</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and appending Client ID\n",
    "# initialization\n",
    "datafile = pd.DataFrame()\n",
    "datafile_tp = pd.DataFrame()\n",
    "fieldlist = []\n",
    "directory_in = r'C:\\Temp\\Text Files'\n",
    "directory_out = r'C:\\Temp\\Text Files Final'\n",
    "# Looping, extrating client id, and writing client id to file\n",
    "i=1 # initializing the nth file incrementer\n",
    "j=1 # initializing the nth set of files incrementer\n",
    "for subdir, dirs, files in os.walk(directory_in):\n",
    "    for filename in files: \n",
    "        client_id = filename[10: 20: 1]\n",
    "        in_file_path = subdir + os.sep + filename \n",
    "        datafile_tp = pd.read_csv(in_file_path)\n",
    "        index = 0\n",
    "        while index < len(datafile_tp):\n",
    "            fieldlist.append(client_id) \n",
    "            index = index + 1\n",
    "        datafile_tp ['CLIENT ID'] = fieldlist\n",
    "        datafile = pd.concat([datafile, datafile_tp])\n",
    "#         print(\"client_id:\"+str(client_id))\n",
    "#         print(\"datafile.shape:\" + str(datafile.shape))\n",
    "        datafile_tp=pd.DataFrame()\n",
    "        fieldlist=[]\n",
    "        mp = i/15 # parameter to find the nth set of files. this quarantee that each final concantemated data file is composed of the max 15 original data files.\n",
    "#         print(\"mp:\"+str(mp))\n",
    "#         print(\"j:\"+str(j))\n",
    "#         print(\"i:\"+str(i))\n",
    "        if mp>=j:\n",
    "            filename_final = \"Merge_\" + str(j) + \".txt\" \n",
    "            directory_out_nth_file =  directory_out + os.sep + filename_final\n",
    "            datafile.to_csv(directory_out_nth_file)\n",
    "            datafile=pd.DataFrame()\n",
    "#             print(\"client_id:\"+str(client_id))\n",
    "#             print(\"datafile.shape, inside if:\" + str(datafile.shape))\n",
    "#             print(\"mp:\"+str(mp))\n",
    "#             print(\"j:\"+str(j))\n",
    "#             print(\"i:\"+str(i))\n",
    "            j=j+1 # the nth set of files incrementer\n",
    "        i=i+1 # the nth file incrementer\n",
    "    filename_final = \"Merge_\" + str(j) + \".txt\" \n",
    "    directory_out_nth_file =  directory_out + os.sep + filename_final\n",
    "    datafile.to_csv(directory_out_nth_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223492, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
